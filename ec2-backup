#!/usr/bin/env python

import os
import time
import sys
import ConfigParser
import argparse
import random

class EC2BackupError(Exception):
    pass
RESOURCES = []

VERBOSE = os.environ.get("EC2_BACKUP_VERBOSE") is not None

"""
In case the user tries to run this script on a system that
does not have boto installed, give them a helpful error.
"""
try:
    import boto
    from boto.ec2.connection import EC2Connection
except ImportError:
    print "Missing required dependency: boto"
    print "Please see: https://github.com/boto/boto"
    sys.exit(1)

"""
Produce an information message
"""
def info(msg):
    if VERBOSE:
        print "[INFO] " + msg 

"""
Produce a non-fatal error message
"""
def warn(msg):
    print "[WARN] " + msg

"""
Fail with an error message
"""
def fatal(reason, exit_code=1):
    print "[ERROR] " + reason
    raise EC2BackupError()

"""
Try and reach a system over ssh
"""
def canConnect(keypairPath, ip):
    info("trying to test ssh connectivity to instance")
    if os.system("ssh -i %s fedora@%s 'echo  > /dev/null' ".format(keypairPath, ip)) == 0:
        return True
    return False

try:
    parser = argparse.ArgumentParser(description="Create backups in the Amazon Cloud")
    parser.add_argument('-m', '--method', default='dd')
    parser.add_argument('-v', '--volume', default=None)
    parser.add_argument('-h', '--help', default=None)
    args = parser.parse_args(sys.argv[1:])
except:
    raise

if args.help is not None:
    print "ec2-backup -- backup a directory into Elastic Block Storage (EBS)"
    print "ec2-backup [-h] [-m method] [-v volume-id] dir"


# read AWS config file
config = ConfigParser.ConfigParser()
cfg_file_path = os.environ.get('AWS_CONFIG_FILE')

if cfg_file_path is None:
    fatal("No config file defined; Please set 'AWS_CONFIG_FILE' in your environment")

try:
    with open(cfg_file_path) as cfg_fp:
        config.readfp(cfg_fp)
except IOError:
    fatal("Failed to open config file: %s" % (cfg_file_path))

# set properties
try:
    ACCESS_KEY = config.get('default', 'aws_access_key_id')
except ConfigParser.NoOptionError:
    fatal("Unable to read access key id. Is 'aws_access_key_id' defined in %s in section [default]?" % (cfg_file_path))

try:
    SECRET_KEY = config.get('default', 'aws_secret_access_key')
except ConfigParser.NoOptionError:
    fatal("Unable to read secret access key. Is 'aws_secret_access_key' defined in %s in section [default]?" % (cfg_file_path))

CREDENTIALS = {
    'aws_access_key_id': ACCESS_KEY,
    'aws_secret_access_key': SECRET_KEY
}

# Possible TODO: allow user to specify instance type in AWS_BACKUP_ARGS
AMI_IMAGE_ID    = 'ami-3b361952' # Fedora
KEY_NAME        = os.environ.get('EC2_PRIVATE_KEY')
INSTANCE_TYPE   = 't1.micro'
AWS_AZ          = 'us-east-1' # AZ stands for Availability Zone
SECURITY_GROUP  = 'ec2-backup-default'
BCKUPSRCDIR     = sys.argv[-1] # Directory to backup, should be last command line option
DEVICE          = '/dev/sdf'
TMP_DIR         = '/tmp'
VOLUME_ID       = args.volume # will be None if unspecified
METHOD          = args.method
UPDATE_TIMEOUT  = 5*60 # 5 minute maximum wait time (in seconds)

if METHOD not in ['dd', 'rsync']:
    fatal('invalid method; please specify one of (%s) using -m/--method' % ("|".join(ALLOWED_METHODS)))

try:
    # Create a Connection to AWS
    # TODO Error checking
    # what error checking is needed here?
    info("Connecting to %s..." % (AWS_AZ))

    conn = boto.ec2.connect_to_region(AWS_AZ, **CREDENTIALS)

    if conn is None:
        info("Connection fataled; troubleshooting...")
        regions = boto.ec2.regions(**CREDENTIALS)
        if not any(r.name == AWS_AZ for r in regions):
            fatal("Invalid region '%s'; Available regions: %s" % (AWS_AZ, ", ".join([r.name for r in regions])))
        fatal("Failed to initialize EC2 connection")


    """
    Create a KeyPair to use
    Rather than forcing the user to configure their keypair and get it
    from the environment variables, let's just make a new single-use keypair
    for this session. Being as we'll never connect to this instance again,
    we can create the keypair, use it, and then dispose of it.
    """
    KEYPAIRNAME = 'ec2-backup-%s' % (str(random.randint(0, int(10E10))).zfill(10))
    key = conn.create_key_pair(KEYPAIRNAME)
    RESOURCES.append(('keypair', key))
    if key.save(TMP_DIR):
        info("Successfully saved KeyPair to: %s" % (TMP_DIR))
    else:
        fatal("Unable to save the KeyPair. Are you able to write to %s?" % (TMP_DIR))

    """
    Create the Security Group to use if it does not exist
    Check if we have the security group that we need for SSH access. If
    not, then create one for the user so they don't have to configure it.
    """
    try:
        info('Checking for existing security group: %s' % (SECURITY_GROUP))
        group = conn.get_all_security_groups(groupnames=SECURITY_GROUP)[0]
        info('Found security group: %s' % (SECURITY_GROUP))

    except conn.ResponseError, e:
        if e.code == 'InvalidGroup.NotFound':
            info('Creating Security Group: %s' % (SECURITY_GROUP))
            group = conn.create_security_group(SECURITY_GROUP, 'Automatically generated by ec2-backup')
            group.authorize('tcp', 22, 22, '0.0.0.0/0')
        else:
            warn('Failed to find a Security Group; trying to use "%s"' % (SECURITY_GROUP))

    """
    Start an EC2 instance
    """
    info("Starting a remote machine...")
    resrv = conn.run_instances(AMI_IMAGE_ID,        \
                key_name=KEYPAIRNAME,               \
                instance_type=INSTANCE_TYPE,        \
                security_groups=[SECURITY_GROUP])

    # Wait for instance state to be running
    instance = resrv.instances[0]
    RESOURCES.append(('instance', instance))

    # Timeout after waiting too long
    instanceTimeout = 0
    info("Waiting for remote machine to start...")
    while not instance.state == 'running':
        if instanceTimeout >= UPDATE_TIMEOUT:
            raise EC2BackupError("Machine has not updated despite waiting %s seconds".format(UPDATE_TIMEOUT))
        time.sleep(10)
        info("Checking if the machine is ready...")
        instance.update()
        instanceTimeout += 10

    info('Instance Ready. Instance ID: ' + instance.id)

    if canConnect(TMP_DIR+"/"+KEYPAIRNAME+".pem", instance.ip_address):
        info("was able to connect to ec2 instance")
    else:
        fatal("could not connect to ec2 instance over ssh")

    """
    Mount EBS volume to new instance
    If there was a volume specified, use that. Otherwise, make a new volume.
    """
    if VOLUME_ID is not None:
        info('Looking up volume with id: "%s"' % (VOLUME_ID))
        volumes = conn.get_all_volumes(volume_ids=VOLUME_ID) #Get all volumes assocated with the current Instance
        if len(volumes) != 1:
            fatal('Failed to load remote volume with id: "%s"' % (VOLUME_ID))
        info("Got the volume")
        volume = volumes[0]

        if volume.status == 'in-use':
            fatal("specified volume is already in use")
    else:
        info("Creating a new volume...")
        # Possible TODO: determine size of volume from source directory
        volume = conn.create_volume(10, AWS_AZ)

        RESOUCES.append(('volume', volume))

        volumeTimeout = 0
        info("Waiting for the volume to become available...")
        while volume.status != 'available':
            if volumeTimeout >= UPDATE_TIMEOUT:
                raise EC2BackupError("volume not available despite waiting %s seconds".format(UPDATE_TIMEOUT))
            time.sleep(5)
            info("Checking if the volume is ready...")
            volume.update()
            volumeTimeout += 5
    
    info("Trying to attach volume to instance")
    if volume.attach(instance.id, DEVICE): #attach volume
        info("Successfully attached storage volume.")
    else:
        fatal("Failed to attach volume")

    info('Volume is attached')

# TODO: if method is rsync, create filesystem on newly attached volume if none exists (/dev/xvdf)

# TODO This line is confusing and a bit heavy. I don't want to touch it because I don't
# fully understand it yet, but it definitely need to be refactored.
    os.system("ssh -t -t {0} ec2-user@{1} \"sudo mkdir -p /mnt/data-store && sudo mount {2} /mnt/data-store && echo 'Defaults !requiretty' | sudo tee /etc/sudoers.d/rsync > /dev/null\"".format(SSH_OPTS, instance.public_dns_name, DEVICE))

    # Initiate Rsync
    info('Synchronizing directory with AWS')

    for dir in BCKUPSRCDIR:
        """
        Options explained
        -e Specify the remote shell to use (ssh with options)
        -a Archive mode; recursive and preserve meta info
        -v Verbose output
        -z Compress the data being transferred
        --rsync-path Set the path to the rsync executable on remote host
        """
        # TODO Refactor so that this is more easily understandable
        os.system("rsync -e \"ssh {0}\" -avz --delete --rsync-path=\"sudo rsync\" {2} ec2-user@{1}:/mnt/data-store{2}".format(SSH_OPTS, instance.dns_name, backup_dir))

    info('Transfer complete')

# Unmount EBS volume and terminate the instance
    info('Detaching volume from EC2 Instance and Terminating Instance')

# TODO Document
    os.system("ssh -t -t {0} ec2-user@{1} \"sudo umount /mnt/data-store\"".format(SSH_OPTS, instance.dns_name))

# TODO Error checking + document
    volume.detach()
    while not volumeattach.status == 'available':
        time.sleep(10) # Wait for the volume to detatch
        volume.update()

# TODO Remove this or document why it is necessary
    time.sleep(5)

    info('Volume detatched succesfully')

# TODO Error checking (?)
    instance.terminate()

    info('EC2 Instance terminated successfully')

except e:
    # TODO: shouldn't this be warn(e)?
    print e
    if len(RESOURCES) > 0:
        warn("Cleaning up...")

        # TODO: should we look into deleting our custom security group after we are done?

        for key, obj in reversed(RESOURCES):
            if key == 'keypair':
                info("Deleting keypair...")
                obj.delete()
            elif key == 'instance':
                if obj.state == 'running':
                    info("Terminating instance...")
                    obj.terminate()
            elif key == 'volume':
                if obj.status == 'available':
                    info("Deleting allocated volume...")
                    obj.detach()
                    obj.delete()


