#!/usr/bin/env python

import os
import time
import sys
import ConfigParser
import argparse
import random

class EC2BackupError(Exception):
    pass
RESOURCES = []

VERBOSE = os.environ.get("EC2_BACKUP_VERBOSE") is not None

"""
In case the user tries to run this script on a system that
does not have boto installed, give them a helpful error.
"""
try:
    import boto
    from boto.ec2.connection import EC2Connection
except ImportError:
    print "Missing required dependency: boto"
    print "Please see: https://github.com/boto/boto"
    sys.exit(1)

"""
Produce an information message
"""
def info(msg):
    if VERBOSE:
        print "[INFO] " + msg 

"""
Produce a non-fatal error message
"""
def warn(msg):
    print "[WARN] " + msg

"""
Fail with an error message
"""
def fatal(reason, exit_code=1):
    print "[ERROR] " + reason
    raise EC2BackupError()

"""
Try and reach a system over ssh
"""
def canConnect(keypairPath, ip):
    info("trying to test ssh connectivity to instance")
    # TODO: possibly add -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no to ssh args 
    # it will either complain about hosts file or ask that you accept/deny new hosts key without these flags
    if os.system("ssh -i %s fedora@%s 'echo  > /dev/null' " % (keypairPath, ip)) == 0:
        return True
    return False

try:
    parser = argparse.ArgumentParser(description="Create backups in the Amazon Cloud")
    parser.add_argument('-m', '--method', default='dd')
    parser.add_argument('-v', '--volume', default=None)
    args = parser.parse_args(sys.argv[1:-1])
except:
    raise

if 'help' in args:
    print "ec2-backup -- backup a directory into Elastic Block Storage (EBS)"
    print "ec2-backup [-h] [-m method] [-v volume-id] dir"


# read AWS config file
config = ConfigParser.ConfigParser()
cfg_file_path = os.environ.get('AWS_CONFIG_FILE')

if cfg_file_path is None:
    fatal("No config file defined; Please set 'AWS_CONFIG_FILE' in your environment")

try:
    with open(cfg_file_path) as cfg_fp:
        config.readfp(cfg_fp)
except IOError:
    fatal("Failed to open config file: %s" % (cfg_file_path))

# set properties
try:
    ACCESS_KEY = config.get('default', 'aws_access_key_id')
except ConfigParser.NoOptionError:
    fatal("Unable to read access key id. Is 'aws_access_key_id' defined in %s in section [default]?" % (cfg_file_path))

try:
    SECRET_KEY = config.get('default', 'aws_secret_access_key')
except ConfigParser.NoOptionError:
    fatal("Unable to read secret access key. Is 'aws_secret_access_key' defined in %s in section [default]?" % (cfg_file_path))

CREDENTIALS = {
    'aws_access_key_id': ACCESS_KEY,
    'aws_secret_access_key': SECRET_KEY
}

# Possible TODO: allow user to specify instance type in AWS_BACKUP_ARGS
AMI_IMAGE_ID    = 'ami-3b361952' # Fedora
KEY_NAME        = os.environ.get('EC2_PRIVATE_KEY')
INSTANCE_TYPE   = 't1.micro'
AWS_AZ          = 'us-east-1' # AZ stands for Availability Zone
SECURITY_GROUP  = 'ec2-backup-default'
BCKUPSRCDIR     = sys.argv[-1] # Directory to backup, should be last command line option
DEVICE          = '/dev/sdf'
TMP_DIR         = '/tmp'
VOLUME_ID       = args.volume # will be None if unspecified
METHOD          = args.method
UPDATE_TIMEOUT  = 5*60 # 5 minute maximum wait time (in seconds)

# TODO: if VOLUME_ID is specified, get zone for volume and set AWS_AZ to that ZONE. we need instance and volume to be in the same region

if METHOD not in ['dd', 'rsync']:
    fatal('invalid method; please specify one of (%s) using -m/--method' % ("|".join(ALLOWED_METHODS)))

try:
    # Create a Connection to AWS
    # TODO Error checking
    # what error checking is needed here?
    info("Connecting to %s..." % (AWS_AZ))

    conn = boto.ec2.connect_to_region(AWS_AZ, **CREDENTIALS)

    if conn is None:
        info("Connection fataled; troubleshooting...")
        regions = boto.ec2.regions(**CREDENTIALS)
        if not any(r.name == AWS_AZ for r in regions):
            fatal("Invalid region '%s'; Available regions: %s" % (AWS_AZ, ", ".join([r.name for r in regions])))
        fatal("Failed to initialize EC2 connection")


    """
    Create a KeyPair to use
    Rather than forcing the user to configure their keypair and get it
    from the environment variables, let's just make a new single-use keypair
    for this session. Being as we'll never connect to this instance again,
    we can create the keypair, use it, and then dispose of it.
    """
    KEYPAIRNAME = 'ec2-backup-%s' % (str(random.randint(0, int(10E10))).zfill(10))
    key = conn.create_key_pair(KEYPAIRNAME)
    RESOURCES.append(('keypair', key))
    if key.save(TMP_DIR):
        info("Successfully saved KeyPair to: %s" % (TMP_DIR))
    else:
        fatal("Unable to save the KeyPair. Are you able to write to %s?" % (TMP_DIR))

    """
    Create the Security Group to use if it does not exist
    Check if we have the security group that we need for SSH access. If
    not, then create one for the user so they don't have to configure it.
    """
    try:
        info('Checking for existing security group: %s' % (SECURITY_GROUP))
        group = conn.get_all_security_groups(groupnames=SECURITY_GROUP)[0]
        info('Found security group: %s' % (SECURITY_GROUP))

    except conn.ResponseError, e:
        if e.code == 'InvalidGroup.NotFound':
            info('Creating Security Group: %s' % (SECURITY_GROUP))
            group = conn.create_security_group(SECURITY_GROUP, 'Automatically generated by ec2-backup')
            group.authorize('tcp', 22, 22, '0.0.0.0/0')
        else:
            warn('Failed to find a Security Group; trying to use "%s"' % (SECURITY_GROUP))

    """
    Start an EC2 instance
    """
    info("Starting a remote machine...")
    resrv = conn.run_instances(AMI_IMAGE_ID,        \
                key_name=KEYPAIRNAME,               \
                instance_type=INSTANCE_TYPE,        \
                security_groups=[SECURITY_GROUP])

    # Wait for instance state to be running
    instance = resrv.instances[0]
    RESOURCES.append(('instance', instance))

    # Timeout after waiting too long
    instanceTimeout = 0
    info("Waiting for remote machine to start...")
    while not instance.state == 'running':
        if instanceTimeout >= UPDATE_TIMEOUT:
            raise EC2BackupError("Machine has not updated despite waiting %s seconds".format(UPDATE_TIMEOUT))
        time.sleep(10)
        info("Checking if the machine is ready...")
        instance.update()
        instanceTimeout += 10

    info('Instance Ready. Instance ID: ' + instance.id)

    initializationTimedOut = 0
    doneInitializingInstance = False
    while initializationTimedOut < 5*60: # 5 minutes
        if doneInitializingInstance:
            info("system initialized")
            break
        instance_statuses_list = conn.get_all_instance_status(instance_ids = [instance.id])
        if(len(instance_statuses_list) == 1):
            currentSystemStatus = instance_statuses_list[0].system_status
            currentInstanceStatus = instance_statuses_list[0].instance_status
            info("system status: '%s'   instance status: '%s'" % (currentSystemStatus, currentInstanceStatus))
            if currentSystemStatus == 'Status:initializing' or currentInstanceStatus == 'Status:initializing':
                info("waiting for system initialization to finish")
                time.sleep(20)
                initializationTimedOut += 20
            else:
                info("!system status: '%s'   instance status: '%s'" % (currentSystemStatus, currentInstanceStatus))
                doneInitializingInstance = True
        else:
            fatal("unable to get system status. # instances found when searching for status is "+len(instance_statuses_list))
    
    if not doneInitializingInstance:
        fail("instance initialization timed out")

    if canConnect(TMP_DIR+"/"+KEYPAIRNAME+".pem", instance.ip_address):
        info("was able to connect to ec2 instance")
    else:
        fatal("could not connect to ec2 instance over ssh")

    """
    Mount EBS volume to new instance
    If there was a volume specified, use that. Otherwise, make a new volume.
    """
    if VOLUME_ID is not None:
        info('Looking up volume with id: "%s"' % (VOLUME_ID))
        volumes = conn.get_all_volumes(volume_ids=VOLUME_ID) #Get all volumes assocated with the current Instance
        if len(volumes) != 1:
            fatal('Failed to load remote volume with id: "%s"' % (VOLUME_ID))
        info("Got the volume")
        volume = volumes[0]

        if volume.status == 'in-use':
            fatal("specified volume is already in use")

        # TODO: check if volume placement is different than the instance placement. can only attach if in same region
    else:
        info("Creating a new volume...")
        # Possible TODO: determine size of volume from source directory
        volume = conn.create_volume(10, instance.placement)

        RESOURCES.append(('volume', volume))

        volumeTimeout = 0
        info("Waiting for the volume to become available...")
        while volume.status != 'available':
            if volumeTimeout >= UPDATE_TIMEOUT:
                raise EC2BackupError("volume not available despite waiting %s seconds".format(UPDATE_TIMEOUT))
            time.sleep(5)
            info("Checking if the volume is ready...")
            volume.update()
            volumeTimeout += 5
    
    info("Trying to attach volume to instance")
    if volume.attach(instance.id, DEVICE): #attach volume
        info("Successfully attached storage volume.")
    else:
        fatal("Failed to attach volume")

    info('Volume is attached')

# TODO: if method is rsync, create filesystem on newly attached volume if none exists (/dev/xvdf)
# http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.html
# sudo file -s /dev/xvdf
# /dev/xvdf: data
# ^ if we see this output then we know that there is no filesystem
# make one with sudo mkfs -t ext4 /dev/xvdf
# the file command does not appear to be installed on fedora by default so we may have to change AMI's
# finally, mount file system: 
# mkdir -p /mnt/data-store
# mount /dev/xvdf /mnt/data-store

# TODO This line is confusing and a bit heavy. I don't want to touch it because I don't
# fully understand it yet, but it definitely need to be refactored.
    os.system("ssh -t -t {0} ec2-user@{1} \"sudo mkdir -p /mnt/data-store && sudo mount {2} /mnt/data-store && echo 'Defaults !requiretty' | sudo tee /etc/sudoers.d/rsync > /dev/null\"".format(SSH_OPTS, instance.public_dns_name, DEVICE))

    # Initiate Rsync
    info('Synchronizing directory with AWS')

    for dir in BCKUPSRCDIR:
        """
        Options explained
        -e Specify the remote shell to use (ssh with options)
        -a Archive mode; recursive and preserve meta info
        -v Verbose output
        -z Compress the data being transferred
        --rsync-path Set the path to the rsync executable on remote host
        """
        # TODO Refactor so that this is more easily understandable
        os.system("rsync -e \"ssh {0}\" -avz --delete --rsync-path=\"sudo rsync\" {2} ec2-user@{1}:/mnt/data-store{2}".format(SSH_OPTS, instance.dns_name, backup_dir))

    info('Transfer complete')

# Unmount EBS volume and terminate the instance
    info('Detaching volume from EC2 Instance and Terminating Instance')

# TODO Document
    os.system("ssh -t -t {0} ec2-user@{1} \"sudo umount /mnt/data-store\"".format(SSH_OPTS, instance.dns_name))

# TODO Error checking + document
    volume.detach()
    volume.update()
    while not volumeattach.status == 'available':
        time.sleep(10) # Wait for the volume to detatch
        volume.update()

# TODO Remove this or document why it is necessary
    time.sleep(5)

    info('Volume detatched succesfully')

# TODO Error checking (?)
    instance.terminate()

    info('EC2 Instance terminated successfully')

except Exception, e:
    # TODO: shouldn't this be warn(e)?
    print e
    if len(RESOURCES) > 0:
        warn("Cleaning up...")

        # TODO: should we look into deleting our custom security group after we are done?

        for key, obj in reversed(RESOURCES):
            if key == 'keypair':
                info("Deleting keypair...")
                obj.delete()
                try:
                    os.remove(TMP_DIR+"/"+KEYPAIRNAME+".pem")
                except:
                    info("could not remove security key %s" % TMP_DIR+"/"+KEYPAIRNAME+".pem")
            elif key == 'instance':
                # creating an instance automatically creates an ebs volume.
                # find and delete that ebs volume as well (should be attached).
                # we should be careful that this part runs after 'volume' as we dont want to accidentally delete the volume we stored data too
                # TODO: find and delete that volume
                if obj.state == 'running':
                    info("Terminating instance...")
                    obj.terminate()
                else:
                    info("instance already terminated")
            elif key == 'volume':
                if obj.status == 'available' or obj.status == 'in-use':
                    info("Deleting allocated volume...")
                    obj.update()
                    volumeDetached = obj.detach()
                    obj.update()
                    detachForced = False
                    if not volumeDetached:
                        detachForced = obj.detach(force=True)
                        obj.update()

                    if not volumeDetached and not detachForced:
                        print "could not detach volume from instance"

                    # wait here for it to be detached first. if its still detaching at time of deletion it will crash
                    volumeTimeout = 0
                    info("Waiting for the volume to become available...")
                    # fix this. you must wait for some other status 
                    info("Checking if the volume is detached...")
                    while obj.status != 'available':
                        if volumeTimeout >= UPDATE_TIMEOUT*5:
                            break
                        time.sleep(5)
                        info("Checking if the volume is detached...")
                        obj.update()
                        volumeTimeout += 5
                    info("current volume status: "+obj.status)

                    try:
                        if VOLUME_ID is None:
                            # you only want to delete the volume on cleanup if we personally created the volume during program execution
                            obj.delete()
                    except Exception, vex:
                        print "could not delete volume: "
                        print vex
                else:
                    info("volume not available or in-use")
            else:
                info("unrecognized key when cleaning up RESOUCES: key=%s" % key)

